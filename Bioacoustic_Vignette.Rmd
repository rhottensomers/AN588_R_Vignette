---
title: "Bioacoustic Vignette"
author: "Reese Hotten-Somers"
date: "2023-10-26"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# TO DO:
Typical frequency ranges for humans, apes, birds, bats, frogs, and whales/dophins
Comments
Challenges

## Intro to Bioacoustics:

What is bioacoustics, who uses it, and how is it implemented? 

*this is unfinishied*
Broadly, bioacoustics is the the crossdisciplinary science of biology and acoustics that studies the production, transmission, and reception of animal sounds. Given the wide range of information that bioacoustics provides, it's used by researchers, physicians, and government agencies.Studying sounds and it's affects on living organisms, can provide powerful insight to structure and dynamics of ecosystems, species biodiversity, habitat health, organismal health, information climate change, and much more. 


## Preliminaries
Install packages: {bioacoustics}, {warbleR}, {randomForest}, {Rraven}

## Objectives


## Load in Packages
```{r, prelims}
library(warbleR)
library(bioacoustics)
library(tools)
library(randomForest)



```

# Importing Data from the internet
Warblr comes with the function query_xc which allows you to seamlessly import audio data from xeno-canto[https://xeno-canto.org/484847].
```{r, importing}
#pulling all Strepera versicolor calls without downloading locally
df1 = query_xc(qword ='Strepera versicolor type:call cnt:"Australia"', download = FALSE) #todo: include explanation for parameters of query_xc

#Filter by type   
df1 = df1[df1$Vocalization_type=="call",]
df1 = df1[df1$Quality=="A",]
df1 = df1[1:9,]
View(df1)

#Download data to working directory
query_xc(X = df1, download = TRUE, path = getwd())

```

# Importing Your Own Data

Great! Now that we know how to load in data from an cloud-based data set, lets try something that will probably be more useful in your own future research endeavor. Say you are a ecologist who has just come back from a field expedition where you set up passive bio-acoustic monitors. All the recorded audio files (usually in .mp3 or .wav formats) are saved in a harddrive. How would you import your data then?    

You can import you files straight from your Harddrive, Desktop or anywhere else on your personal computer. No need for cloud storage! The following code reads in a file names *mgr.wav* which, for the purpose of this example, has been saved in your working directory. 

```{r, importing_mp3}
# getwd() gets our current working directory and file.path() combines getwd() and "mgr.wav" into a file path format. 
wav <- read_audio(file.path(getwd(), "mgr.wav"))

# Say you have a file saved on your Desktop, your code might look a little like this:
# wav <- read_audio(file.path("~/Desktop", "mgr.wav"))
```

Now that we know how to read files, lets load in a file named "Strepera-versicolor-571957.mp3". 

While reading in one file at a time is helpful, an ecologist returning from a month long expedition will surely have more than one file to read. We have written a funciton here that will read all the mp3 files in your working directory. You could expand on this funciton to read files in different directories or even create a data frame!

```{r, readf}
# Read just one file!
STREPV <- read_audio(file.path(getwd(), "Strepera-versicolor-571957.mp3"))
STREPV


# Read all the files in your current directory!
read_all_mp3 <- function(){
  # List all mp3 files in current directory
  mp3_files = list.files(path=".", pattern=".mp3", all.files=TRUE, 
                         full.names=TRUE)
  audio_list <- list()
  # Append all the files a paths to a single list named audio_list
  for(files in mp3_files) {
    curr_file_path <- read_audio(file.path(files))
    audio_list <- append(audio_list, curr_file_path)
  }
  return(audio_list)
}

read_all_mp3()

# TO DO: DELETE THIS (I DONT THINK WE NEED IT)
#Reading a wave object: Duration, file length/durations
#Number of samples, number of intervals taken from the file
#Sample rate, the rate of each sample taken. Here's a nice visual[https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Signal_Sampling.svg/1920px-Signal_Sampling.svg.png]
  #You can find number of samples by multiplying the Samplingrate by Duration
#Channels: Is the audio recorded from one source or "channel"(mono) or multiple channels (stereo)
#PCM is a method used to "digitally represent sampled analog signals."
#Bit is the number of bit per sample
```

```{r, plotp}
# Display with spectro()
ticks <- c(from = 1000, to = 20000, by = 1000)

temp_slice <- c(from = 1, to = 10) # in seconds

plot(STREPV)

#Let's zoom in
plot(STREPV, xlim = c(3, 5)) #This is a waveform,  x axis is the time of the file and the yaxis is a amplitude, or the displacement of a particle
```


```{r, steroplot}
STREPV2 <- read_audio(file.path(getwd(), "Strepera-versicolor-743906.mp3"))
STREPV2
plot(STREPV2)
```

```{r, spectro}
spectro(STREPV, tlim = temp_slice, FFT_size = 512, ticks_y = ticks) #sets the y axis labeling, in Hz, so its 1 kHz to 100 kHz, in 1 kHz interval
```
NOTE: Y axis is frequency in hertz and X axis is time. However spectro() does not have the ability to add x axis label so it should only be used for visualization. 

```{r, fspec}
image(fspec(STREPV, tlim = temp_slice, rotate = TRUE)) #A matrix of amplitude or decibel (dB) values in the time / frequency domain.

# col = hcl.colors(20, "viridis", rev = TRUE
```

NOTE: If you have older zero-crossing bat vocalization patterns, then the functions write_zc() and plot_zc() will serve as replacements for fspec() and spectro(). (Add in paragraph after running through spectro and fspec() with an asterisk)

# Plotting the data

```{r, plot_data}


# blob_detection
?blob_detection
blob_detect <- blob_detection(
  STREPV, time_exp = 10, FFT_size = 512, settings = FALSE, acoustic_feat = TRUE,
  metadata = FALSE, spectro_dir = file.path(getwd(), "Spectros"), time_scale = 0.1, ticks = TRUE)
blob_detect

# Threshold_detection
?threshold_detection
TD <- threshold_detection(
  STREPV, 
  threshold = 12,   time_exp = 1,  min_dur = 140,   max_dur = 440,   min_TBE = 10,  max_TBE = 5000, 
  EDG = 0.996, 
  LPF = 10000, 
  HPF = 1000, 
  FFT_size = 256, 
  FFT_overlap = 0.875, 
  start_thr = 20, 
  end_thr = 30, 
  SNR_thr = 8, 
  angle_thr = 125, 
  duration_thr = 440, 
  NWS = 1000, 
  KPE = 1e-05, 
  KME = 1e-04, 
  settings = FALSE, 
  acoustic_feat = TRUE, 
  metadata = FALSE, 
  spectro_dir = file.path(getwd(), "Spectros"), 
  time_scale = 1, 
  ticks = TRUE
)
TD


# auto_detec automatically detects the start and end of vocalizations in sound files based on amplitude, duration, and frequency range attributes.
# https://rdrr.io/cran/warbleR/man/auto_detec.html
?auto_detec
detection <- auto_detec(threshold = 5, ssmooth = 300, bp = c(2, 9), wl = 300, path = getwd())
detection

#Warning: This function will be deprecated in future warbleR versions, please look at the ohun package for automatic signal detection functions 
library(ohun)
library(viridis)

detection$sound.files
label_spectro(wave = STREPV, detection = detection[detection$sound.files == "Strepera-versicolor-571957.mp3", ], hop.size = 10, ovlp = 50, flim = c(1, 10), fastdisp=TRUE) 
```

# *CHALLENGE*
1. Record an audio file of you saying something (around 30 seconds!)
2. Transfer that file onto your laptop. Save it whereever you'd like!
3. Read in the mp3 file. 
4. Plot the spectrogram from 10-20 seconds of the audio file.
5. Run a detection algorithm on your file and plot the detection results.

``` {r Challenge Code}
wav <- read_audio(file.path("~/Desktop", "your_file_name.wav"))
temp_slice <- c(from = 10, to = 20) # in seconds
ticks <- c(from = 1000, to = 20000, by = 1000)
spectro(wav, tlim = temp_slice, FFT_size = 512, ticks_y = ticks) #sets the y axis labeling, in Hz, so its 1 kHz to 100 kHz, in 1 kHz interval
detection <- auto_detec(threshold = 5, ssmooth = 300, bp = c(2, 9), wl = 300, path = getwd())

library(ohun)
library(viridis)
label_spectro(wave = wav, detection = detection[detection$sound.files == "mgr.wav", ], hop.size = 10, ovlp = 50, flim = c(1, 10), fastdisp=TRUE) 
```